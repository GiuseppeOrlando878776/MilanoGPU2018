{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import pycuda.driver as cuda_driver\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "\n",
    "import IPythonMagic\n",
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global logger already initialized!\n"
     ]
    }
   ],
   "source": [
    "%setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering context in user workspace\n",
      "Context already registered! Ignoring\n"
     ]
    }
   ],
   "source": [
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu(6): warning: variable \"gid\" was declared but never referenced\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_src = \"\"\"\n",
    "__global__ void shmemReduction(float* output,float* input,int size) {\n",
    "    // First we stride through global memory and compute \n",
    "    // the maximum for every thread\n",
    "    int gid = blockIdx.x*blockDim.x + threadIdx.x; // blockIdx.x is always zero because we use just one block\n",
    "    \n",
    "    float max_value = -99999999.99;\n",
    "    for(int i = threadIdx.x; i < size; i = i + blockDim.x) {\n",
    "        max_value = fmaxf(max_value, input[i]);\n",
    "    }\n",
    "    // Store the per-thread maximum in temporary\n",
    "    output[threadIdx.x] = max_value;\n",
    "    // Store the per-thread maximum in shared memory\n",
    "    __shared__ float max_shared[64];\n",
    "    max_shared[threadIdx.x] = max_value;\n",
    "    // Synchronize so that all thread see the same shared memory\n",
    "    __syncthreads();\n",
    "    // Find the maximum in shared memory\n",
    "    if(threadIdx.x < 64) {\n",
    "        // Reduce from 128 to 64\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+64]);\n",
    "    }\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x < 32) {\n",
    "        // Reduce from 64 to 32\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+32]);\n",
    "    }\n",
    "    //since we have more than one active warp(threadIdx.x>32) we need to ensure that first they have finished\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x < 16) {\n",
    "        // Reduce from 32 to 16\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+16]);\n",
    "    }\n",
    "    if(threadIdx.x < 8) {\n",
    "        // Reduce from 16 to 8\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+8]);\n",
    "    }\n",
    "    if(threadIdx.x < 4) {\n",
    "        // Reduce from 8 to 4\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+4]);\n",
    "    }\n",
    "    if(threadIdx.x < 2) {\n",
    "        // Reduce from 4 to 2\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+2]);\n",
    "    }\n",
    "    if(threadIdx.x < 1) {\n",
    "        // Reduce from 2 to 1\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+1]);\n",
    "    }\n",
    "    \n",
    "    if(threadIdx.x == 0) {\n",
    "        output[0] = max_shared[0];\n",
    "    }\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "kernel_module = cuda_compiler.SourceModule(kernel_src)\n",
    "kernel_function = kernel_module.get_function(\"shmemReduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0415197  0.27639794 0.6346874  0.79028094 0.530032   0.4325671\n",
      " 0.7446556  0.9761816  0.3398487  0.34358472 0.57067627 0.83579314\n",
      " 0.7921029  0.09663699 0.8544314  0.96140355 0.96576345 0.30608365\n",
      " 0.34680593 0.342454   0.4197055  0.8163652  0.76615626 0.9654034\n",
      " 0.6327166  0.9994929  0.07451115 0.78208333 0.17395048 0.87565994\n",
      " 0.604195   0.9833372  0.8590598  0.7846729  0.8799296  0.03161197\n",
      " 0.39415574 0.2683006  0.57116646 0.17993945 0.6320698  0.00694536\n",
      " 0.831777   0.6938064  0.12514924 0.15839885 0.23094083 0.76098853\n",
      " 0.5474812  0.31646284 0.987259   0.77799374 0.682354   0.7813384\n",
      " 0.30107498 0.15996346 0.87682545 0.24000433 0.02706377 0.72064304\n",
      " 0.84669864 0.2500792  0.8921426  0.22878674 0.07943839 0.4254837\n",
      " 0.11947915 0.8905313  0.76027364 0.65806836 0.561684   0.66613823\n",
      " 0.9329324  0.8083595  0.6425296  0.18666573 0.24283965 0.6791122\n",
      " 0.02231729 0.0996299  0.97998476 0.26803094 0.8298856  0.74105275\n",
      " 0.41594905 0.4402502  0.7306058  0.50981456 0.06163519 0.94104934\n",
      " 0.344616   0.6695245  0.01918166 0.6917783  0.44017687 0.3927229\n",
      " 0.933097   0.58934677 0.79902035 0.5386979  0.96834564 0.3753703\n",
      " 0.8211932  0.5226674  0.5252536  0.2947884  0.9265887  0.06386492\n",
      " 0.53308743 0.6662884  0.769761   0.616693   0.5453959  0.350007\n",
      " 0.4269001  0.7149581  0.69246674 0.35381702 0.61865884 0.27367997\n",
      " 0.44843316 0.70149446 0.405182   0.61875886 0.4627714  0.6697898\n",
      " 0.2736638  0.2912753 ]\n"
     ]
    },
    {
     "ename": "LogicError",
     "evalue": "cuMemAlloc failed: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-e393cf83ff99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0ma_g\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGPUArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0ma_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, shape, dtype, allocator, base, gpudata, strides, order)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgpudata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuMemAlloc failed: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "n = 128;\n",
    "a = np.random.rand(n).astype(np.float32)\n",
    "print(a)\n",
    "\n",
    "a_g = GPUArray(a.shape,dtype=np.float32)\n",
    "a_g.set(a)\n",
    "\n",
    "num_thread = 128 #Each kernel will compute the maximum between two numbers\n",
    "b = np.empty((1,num_thread)).astype(np.float32)\n",
    "b_g = GPUArray(b.shape,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "LogicError",
     "evalue": "cuMemcpyDtoH failed: an illegal memory access was encountered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-38a24c493a27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkernel_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma_g\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mb_g\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, ary, pagelocked, async_, stream, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0m_memcpy_discontig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masync_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pycuda/gpuarray.py\u001b[0m in \u001b[0;36m_memcpy_discontig\u001b[0;34m(dst, src, async_, stream)\u001b[0m\n\u001b[1;32m   1307\u001b[0m                     \u001b[0mdrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_dtoh_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m                     \u001b[0mdrv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemcpy_dtoh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpudata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_as_strided\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLogicError\u001b[0m: cuMemcpyDtoH failed: an illegal memory access was encountered"
     ]
    }
   ],
   "source": [
    "block_size = (num_thread,1,1)\n",
    "grid_size = (1,1,1)\n",
    "\n",
    "kernel_function(b_g,a_g,np.int32(n),grid=grid_size,block=block_size)\n",
    "\n",
    "b_g.get(b)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
