{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "import pycuda.driver as cuda_driver\n",
    "import pycuda.compiler as cuda_compiler\n",
    "from pycuda.gpuarray import GPUArray\n",
    "\n",
    "import IPythonMagic\n",
    "from Timer import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python version 3.6.6 | packaged by conda-forge | (default, Jul 26 2018, 11:48:23) [MSC v.1900 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "%setup_logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registering context in user workspace\n",
      "Creating context\n",
      "PyCUDA version 2018.1.1\n",
      "CUDA version (10, 0, 0)\n",
      "Driver version 10000\n",
      "Using 'GeForce GTX 1050' GPU\n",
      " => compute capability: (6, 1)\n",
      " => memory: 1647 / 2048 MB available\n",
      "Created context handle <1612457349264>\n",
      "Using CUDA cache dir D:\\orlan\\Google Drive\\Corso_GPU\\MilanoGPU2018\\Day2\\cuda_cache\n"
     ]
    }
   ],
   "source": [
    "%cuda_context_handler context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programmi (x86)\\Anaconda3\\envs\\gpudev\\lib\\site-packages\\ipykernel\\__main__.py:109: UserWarning: The CUDA compiler succeeded, but said the following:\n",
      "kernel.cu\n",
      "kernel.cu(10): warning: variable \"gid\" was declared but never referenced\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kernel_src = \"\"\"\n",
    "__global__ void shmemReduction(float* output,float* input,int size,int n_threads) {\n",
    "    if(n_threads > size) {\n",
    "        n_threads = size;\n",
    "    }\n",
    "        \n",
    "    // First we stride through global memory and compute \n",
    "    // the maximum for every thread\n",
    "    int gid = blockIdx.x*blockDim.x + threadIdx.x; // blockIdx.x is always zero because we use just one block\n",
    "    \n",
    "    float max_value = -99999999.99;\n",
    "    for(int i = threadIdx.x; i < size; i = i + blockDim.x) {\n",
    "        max_value = fmaxf(max_value, input[i]);\n",
    "    }\n",
    "    \n",
    "    // Store the per-thread maximum in temporary\n",
    "    output[threadIdx.x] = max_value;\n",
    "    \n",
    "    // Store the per-thread maximum in shared memory\n",
    "    \n",
    "    //__shared__ float max_shared[n_threads];\n",
    "    //__shared__ float* max_shared = new float(n_threads);\n",
    "    \n",
    "    __shared__ float* max_shared;\n",
    "    if(threadIdx.x == 0) {\n",
    "        max_shared = new float(n_threads);\n",
    "    }\n",
    "    __syncthreads();\n",
    "    \n",
    "    max_shared[threadIdx.x] = max_value;\n",
    "    \n",
    "    \n",
    "    // Synchronize so that all thread see the same shared memory\n",
    "    __syncthreads();\n",
    "    \n",
    "    // Reduce up to get the global maximum\n",
    "    \n",
    "    /*--- __shared__ int n_tr = n_threads; *---/\n",
    "    \n",
    "    /*__shared__ int n_tr;\n",
    "    if(threadIdx.x == 0) {\n",
    "        n_tr = n_threads;\n",
    "    }\n",
    "    __syncthreads();\n",
    "    */\n",
    "    \n",
    "    int n_t = n_threads;\n",
    "    while(n_t > 1) {\n",
    "        if((n_t % 2) == 1) {\n",
    "            if(threadIdx.x < (int) n_t/2) {\n",
    "               max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+(int)(n_t/2)+1]);\n",
    "            }\n",
    "            if(threadIdx.x == (int) n_t/2) {\n",
    "                max_shared[(int) n_t/2] = max_shared[threadIdx.x];\n",
    "            }\n",
    "            n_t = (int) n_t/2 + 1;\n",
    "        }\n",
    "        else {\n",
    "            if(threadIdx.x < n_t/2) {\n",
    "               max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+(n_t/2)]);\n",
    "            }\n",
    "            n_t = n_t/2;\n",
    "        }\n",
    "        \n",
    "        if(n_t > 32) {\n",
    "            __syncthreads();\n",
    "        }             \n",
    "    }\n",
    "    \n",
    "    /*\n",
    "    if(threadIdx.x < 32) {\n",
    "        // Reduce from 64 to 32\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+32]);\n",
    "    }\n",
    "    //Since we have more than one active warp(threadIdx.x>32) we need to ensure that first they have finished\n",
    "    __syncthreads();\n",
    "    if(threadIdx.x < 16) {\n",
    "        // Reduce from 32 to 16\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+16]);\n",
    "    }\n",
    "    if(threadIdx.x < 8) {\n",
    "        // Reduce from 16 to 8\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+8]);\n",
    "    }\n",
    "    if(threadIdx.x < 4) {\n",
    "        // Reduce from 8 to 4\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+4]);\n",
    "    }\n",
    "    if(threadIdx.x < 2) {\n",
    "        // Reduce from 4 to 2\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+2]);\n",
    "    }\n",
    "    if(threadIdx.x < 1) {\n",
    "        // Reduce from 2 to 1\n",
    "        max_shared[threadIdx.x] = fmaxf(max_shared[threadIdx.x],max_shared[threadIdx.x+1]);\n",
    "    }\n",
    "    */\n",
    "    \n",
    "    if(threadIdx.x == 0) {\n",
    "        output[0] = max_shared[0];\n",
    "    }\n",
    "    \n",
    "    // Delete the allocated memory to avoid leakage\n",
    "    delete[] max_shared;\n",
    "    \n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "kernel_module = cuda_compiler.SourceModule(kernel_src)\n",
    "kernel_function = kernel_module.get_function(\"shmemReduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.8650922e-01 1.2176803e-01 5.7562840e-01 8.2448352e-04 6.8618017e-01\n",
      " 2.2552863e-01 8.9879340e-01 7.6742530e-01 6.0880017e-01 6.9910079e-01\n",
      " 4.6182546e-01 6.3590991e-01 6.1053497e-01 1.7620215e-01 6.3402981e-01\n",
      " 6.7808330e-01 6.1040664e-01 1.6976602e-01 8.3532876e-01 9.6601784e-01\n",
      " 5.7241720e-01 9.6144706e-01 5.0598097e-01 5.0407541e-01 3.2029536e-01\n",
      " 8.2096383e-02 6.2727332e-01 6.9745332e-01 4.5651048e-01 3.7344590e-02\n",
      " 7.4160850e-01 8.2432610e-01 6.5867132e-01 3.6325777e-01 2.8772461e-01\n",
      " 4.7099930e-01 8.8155526e-01 2.3367505e-01 9.6728468e-01 7.2419119e-01\n",
      " 6.1870855e-01 6.7947310e-01 3.3188987e-01 6.3305962e-01 6.6442388e-01\n",
      " 4.4791740e-01 4.3816480e-01 1.0202161e-01 2.5031471e-01 5.7778811e-01\n",
      " 3.9351609e-02 2.1680520e-01 9.6571755e-01 8.6012983e-01 8.8545673e-02\n",
      " 5.0515994e-02 3.7124911e-01 1.0575325e-01 1.6875978e-01 2.2124602e-01\n",
      " 1.1053295e-01 6.6315573e-01 7.3654050e-01 4.8687893e-01 8.6275950e-02\n",
      " 7.6484716e-01 3.9467329e-01 7.6191354e-01 1.0030141e-01 4.0291214e-01\n",
      " 2.6317653e-01 4.2119303e-01 7.4779743e-01 8.5017659e-02 8.5809278e-01\n",
      " 8.2226706e-01 6.1004025e-01 5.1850075e-01 3.0350995e-01 5.6213415e-01\n",
      " 7.3292708e-01 5.7172072e-01 9.5682889e-01 4.7573727e-01 5.7031053e-01\n",
      " 7.4106234e-01 7.4646014e-01 7.9144591e-01 6.6844380e-01 4.7157642e-01\n",
      " 9.4197398e-01 8.6720043e-01 3.4092337e-02 6.6144097e-01 9.7935629e-01\n",
      " 6.6482556e-01 9.5497298e-01 2.9465488e-01 2.3936561e-01 1.8907306e-01\n",
      " 8.2727605e-01 8.5594296e-01 7.3353142e-02 9.6845353e-01 4.7147936e-01\n",
      " 6.8111938e-01 2.5517273e-01 1.9138026e-01 2.1762682e-01 7.8143084e-01\n",
      " 5.3258389e-01 9.5951056e-01 4.9669912e-01 4.7671312e-01 7.7491719e-01\n",
      " 2.8789431e-02 3.6611012e-01 5.9730124e-01 9.5650956e-02 9.6826941e-01\n",
      " 7.8518730e-01 4.2762673e-01 4.8896331e-01 3.2503492e-01 2.9515627e-01\n",
      " 3.2240205e-02 1.1983488e-01 7.0776981e-01]\n"
     ]
    }
   ],
   "source": [
    "n = 128;\n",
    "a = np.random.rand(n).astype(np.float32)\n",
    "print(a)\n",
    "\n",
    "a_g = GPUArray(a.shape,dtype=np.float32)\n",
    "a_g.set(a)\n",
    "\n",
    "num_thread = 57 #Each kernel will compute the maximum between its thread local part\n",
    "b = np.empty((1,num_thread)).astype(np.float32)\n",
    "b_g = GPUArray(b.shape,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9793563  0.16875978 0.5756284  0.59730124 0.6861802  0.9682694\n",
      "  0.8987934  0.7674253  0.76484716 0.6991008  0.76191354 0.6359099\n",
      "  0.61053497 0.7077698  0.6340298  0.7477974  0.61040664 0.8580928\n",
      "  0.83532876 0.96601784 0.5724172  0.96144706 0.56213415 0.7329271\n",
      "  0.5717207  0.9568289  0.6272733  0.6974533  0.74106234 0.74646014\n",
      "  0.7914459  0.8243261  0.6586713  0.941974   0.86720043 0.4709993\n",
      "  0.88155526 0.9793563  0.9672847  0.954973   0.61870855 0.6794731\n",
      "  0.33188987 0.82727605 0.85594296 0.4479174  0.9684535  0.47147936\n",
      "  0.6811194  0.5777881  0.19138026 0.21762682 0.96571755 0.86012983\n",
      "  0.95951056 0.49669912 0.47671312]]\n",
      "0.9793563\n"
     ]
    }
   ],
   "source": [
    "block_size = (num_thread,1,1)\n",
    "grid_size = (1,1,1)\n",
    "\n",
    "kernel_function(b_g,a_g,np.int32(n),np.int32(num_thread),grid=grid_size,block=block_size)\n",
    "\n",
    "b_g.get(b)\n",
    "\n",
    "#print(a)\n",
    "print(b)\n",
    "print(np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
